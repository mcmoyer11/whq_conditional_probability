y<- function(x) (2*x + 1)
curve(y,xlim=c(-1,1), ylab="y",bty="L")
abline(h=0, v=0, lty=0)
abline(h=0, v=0, lty=0)
load(manipulate)
loadpackage(manipulate)
# Define arrays of points for each of the indep. variables.
# These are the points at which the function will be plotted.
bound = 3    # max distance from the origin along each axis
density = 2  # density of plot points per unit along an axis
x_pts <- seq(-bound,bound,length=2*density*bound+1)
y_pts <- seq(-bound,bound,length=2*density*bound+1)
# Compute the outer (Cartesian) product of the x_pts and y_pts arrays,
# and compute f(x,y) for each (x,y) pair.
# The resulting matrix, f_pts, is a 2-dimensional array of
# f(x,y) values.
f_pts <- outer(x_pts,y_pts,f)
source('~/Downloads/fig_5_17-19.R')
1*.5*.6*.7*.3*1
.5*.6*.7
.4*.1*.5*.21*.5*.4*1
.4*.1*.5*1*.5*.4*.5*.6*.7
.6*.5*.1
.03*.4*.5*.1*.6*.7*.3*.5*.6*.2
.3*1*.5*.6*.2
.018*.7*.6*.1*.5*.4*.03
.03*.5*.21*.018
4.536e-06 + 5.67e-05
(5.67e-05)*(4.536e-06)
6.1236e-05 - 2.571912e-10
source('~/Downloads/R command summary-1.R')
source('~/Downloads/R command summary-1.R')
********************
# Normal Distribution
#********************
dist_mean = .33    # mean of the distribution
dist_sd = .11      # standard deviation of the distribution
# dnorm is the function for the probability density function of
# a normal random variable (defaults to standard normal).
# compute the value of the pdf at point 1.0 with mean = dist_mean and
# standard dev = dist_sd
dnorm(1.0, mean=dist_mean, sd=dist_sd)
# Plot the pdf for the interval from (dist_mean-4) to (dist_mean+4)
curve(dnorm(x, mean=dist_mean, sd=dist_sd), xlim=c(dist_mean-4,dist_mean+4),
ylab="pdf(x)")
# pnorm is the function for the cumulative probability function of
# a normal random variable (defaults to standard normal).
# compute the value of the cpf at point 1.0
pnorm(1.0,dist_mean,dist_sd)
# Plot the cpf for the interval from (dist_mean-4) to (dist_mean+4)
curve(pnorm(x,dist_mean,dist_sd), xlim=c(dist_mean-4,dist_mean+4), xlab="a",
ylab="F(a)")
.11/sqrt(64)
.11/8
.33-1.96*(.01375)
300/500
(.6*(1-.6))/sqrt(500)
0.01073313/sqrt(500)
.6-1.96*0.0004800002
.6-1.96*0.0005
5.64e-5 + 4.536e-6
getwd()
# Anna Goldin R Script
# Last Modified: 2/19/17
setwd("/Users/morgamoyer/Documents/R stats")
#import data
data_raw <- read.table("Experiment 1 Raw Data2.csv", header = TRUE)
# remove unnecessary columns from the data frame
data_raw <- read.table("Experiment 1 Raw Data2.csv", header = TRUE)
install.packages("ggplot")
install.packages("ggplot2")
install.packages(ordinal)
install.packages("tidytext")
data("stop_words")
install.packages("tidyverse")
library(tidyverse)
#Certainty
library(ggplot2)
library(tidyr)
library(dplyr)
#Certainty
library(ggplot2)
library(tidyr)
#  Stats for Con_Prob
# Date: June 2, 2019
############################
# Stats for Likert Study
############################
library(ggplot2)
library(tidyr)
library(dplyr)
library(magrittr)
library(bootstrap)
library(ggpubr)
library(psych)
library(likert)
library(reshape2)
library(lme4)
library(languageR)
library(ordinal)
library(lmerTest)
library(FSA)
library(lattice)
library(boot)
library(rcompanion)
# First, set the working directory
setwd("/Users/morganmoyer/Dropbox/Moyer_research/Embedded_Questions/Dissertation/Conditional_Probability/results/")
source("helpers.R")
# Then import the data in
d <- read.csv("answer.csv", header = TRUE)
d <- d %>% drop_na()
d$likert.f <- as.factor(d$likert)
m <- clm(likert.f ~ answer + modal + wh, data = d, Hess=TRUE)
summary(m)
com <- clm(likert.f ~ task*answer*modal*wh, data = d, link = "logit", Hess=TRUE)
summary(com)
sim <- clm(likert.f ~ task + answer + modal + wh, data = d, link = "logit", Hess=TRUE)
summary(sim)
# in accept, wh was not a significant predictor
# but it was in likely
task <- clm(likert.f ~ task, data = d, link = "logit", Hess=TRUE)
summary(task)
